# vision_transformer_classifier
В данном проекте реализован трансформер (Vision Transformer) на основе предобученной модели из библиотеки timm. Модель обучена с целью идентификации личности с учетом имеющихся ограничений. В реальной ситуации трудности идентификации личности по фотографии могут создавать такие атрибуты, как медицинские маски, шляпы и другое, то есть те объекты, которые закрывают часть лица. 

# Датасет
Для обучения, тестирования и создания базы эмбеддингов был использован публичный датасет CelebA. 
CelebA - обширный датасет из более чем 200 000 изображений знаменитостей, где лица уже отцентрированы.
Для начала работы на гугл-диск был загружен файл `img_align_celeba.zip`. Это архив датасета, полученный с [официального источника](https://mmlab.ie.cuhk.edu.hk/projects/CelebA.html). Кроме того был использован файл `identity_CelebA.txt`, который хранит соответствие каждого изображения из датасета конкретной личности.

# Архитектура модели
Для дообучения был использован трансформер `vit_base_patch16_224.augreg_in21k_ft_in1k` из библиотеки `timm`.
Модель принимает на вход изображения размером 224×224, разбивает их на патчи 16×16, каждый из которых преобразуется в вектор признаков и обрабатывается последовательностью из 12 слоев трансформера (трансформер-блоков). Количество выходных классов в последнем слое классификатора равно количеству личностей.

# Обучение
Для обучения модели был создан собственный класс аугментации данных `MaskAugmentation`, реализующий накладывание "маски". "Маска" закрывает либо верхнюю часть лица (глаза), либо нижнюю часть лица (рот, подбородок).
Для наглядности показан результат применения данного класса аугментаций к изображению:

<img width="300" alt="image" src="https://github.com/user-attachments/assets/1610e514-e844-4fbc-959c-0727171104d8" />


Для дообучения были разморожены параметры последних слоев, а именно 3 блока трансформера, слой нормализации и классификационная голова. Обучение проводилось в 3 эпохи.
Результаты обучения и валидации следующие:

<img width="250" alt="image" src="https://github.com/user-attachments/assets/5b8d49bf-d517-449c-9cf8-e36d80414606" />

# Создание базы эмбеддингов и тестирование модели
После обучения модели последний классификационный слой удаляется и создается база эмбеддингов для последующей идентификации личностей.
Для поиска наиболее близких эмбеддингов использовалась библиотека `faiss`. Чтобы найти близкие вектора необходимо было предварительно их нормализовать, а затем рассчитать косинусное расстояние.
Изображение-запрос (query) подается на вход модели вместе с маской, которая передается в механизм внимания.
Были реализованы следующие маски:
1. Маска, открывающая всю фотографию
2. Маска, открывающая лицо (голову), но скрывающая задний фон
3. Маска, открывающая лицо, но закрывающая волосы и фон
4. Маска, открывающая крайний левый угол изображения минимального размера
Данные маски необходимы для тестирования модели и алгоритма подачи маски в модель. Ожидается, что точность будет максимальной для варианта маски (1), а для маски (4) будет равна точности "случайного угадывания". Использованы следующие метрики: precision@5, precision@10.

<img width="250" alt="image" src="https://github.com/user-attachments/assets/433b7f49-c566-4d14-ab01-67465dd0b1fc" />

Полученные результаты доказывают правильность реализованного алгоритма.





